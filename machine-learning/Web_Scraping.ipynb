{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "db3ca281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4be83730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "880d7a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element_by_id('twotabsearchtextbox')\n",
    "search_button.click()\n",
    "search_button.send_keys(\"analog watches for men\")\n",
    "search_button.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcbeb8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffb89cde",
   "metadata": {},
   "source": [
    "Analysing the automated chrome driver, we can observe that there are 7 total number of pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24926460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76a8e56d",
   "metadata": {},
   "source": [
    "Collecting all the URLs (for each page)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b365b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pages_url = []\n",
    "for i in range(1,8):\n",
    "    all_pages_url.append('https://www.amazon.in/s?k=analog+watches+for+men&page='+str(i)+'&ref=sr_pg_7')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48ebe69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cfc692aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating header files for making http requests\n",
    "HEADERS = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'}\n",
    "base_url = 'https://www.amazon.in/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b3719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f33a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e12c658",
   "metadata": {},
   "source": [
    "# Iterating over each page and finding the link of each watch within the page,\n",
    "# Further iterating over each watch link and extracting the desired data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "24260ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_watches = []                #contains the data of each watch within 7 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7adbcbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in all_pages_url:\n",
    "    response = requests.get(page,headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    \n",
    "    # creating a list of all watches on the current page (links)\n",
    "    curr_watches = []\n",
    "    for i in soup.find_all('a',target = \"_blank\",class_ = 'a-link-normal s-underline-text s-underline-link-text s-link-style'):\n",
    "        curr_watches.append(base_url+i.attrs['href'])\n",
    "    \n",
    "    # extracting the details of each watch\n",
    "    for i in curr_watches:\n",
    "        try:    \n",
    "            response1 = requests.get(i,headers=HEADERS)\n",
    "            soup1 = BeautifulSoup(response1.text,'html.parser')\n",
    "            if str(response1.status_code).startswith('2'):\n",
    "\n",
    "                title = soup1.find(id='title').text.strip()\n",
    "                availability = soup1.find(id='availability').text.strip()\n",
    "                review_counts = int(soup1.find(id='acrCustomerReviewText').text.split()[0].replace(',',''))\n",
    "                ratings = float(soup1.find('span',class_='a-size-base a-color-base').text.strip())\n",
    "                price = float(soup1.find('span',class_='a-price-whole').text.replace(\",\",''))\n",
    "\n",
    "            all_watches.append([title,review_counts,ratings,availability,price])\n",
    "            \n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5747f553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4b0f9ad",
   "metadata": {},
   "source": [
    "# as the data is now extracted, we can convert the data to Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c59e42d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(all_watches,columns=['Title','Reviews',\"Ratings\",\"Availability\",'Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e5cc8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0878929c",
   "metadata": {},
   "source": [
    "Ceating brand feature for each watch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "24cbe5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brand(s):\n",
    "    return s.split()[0]\n",
    "\n",
    "df['Brand'] = df.Title.apply(brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6d62e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-ordering df\n",
    "df = df[['Title',\"Brand\",'Reviews',\"Ratings\",\"Availability\",'Price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "cce21c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the empty values in Availability wihth 'Out of stock'\n",
    "def empty_availability(s):\n",
    "    if s == '':\n",
    "        return 'Out of stock'\n",
    "    else:\n",
    "        return s\n",
    "    \n",
    "df.Availability = df.Availability.apply(empty_availability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c53ec4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally exporting the data as .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d4073c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"raw_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b819ad99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b98f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
